# FashionIQ data nums: 18000

includes:
- ./e2e_composition.yaml

model_config:
  FashionFAE:
    image_encoder:
      type: vit_image_encoder
      params:
        name: vit
        pretrained_model_name: google/vit-base-patch16-224-in21k
        random_init: false
        gradient_checkpointing: false
    visual_embedding_dim: 768
    lr_multiplier: 1

scheduler:
  type: warmup_cosine
  params:
    use_warmup: true
    max: 42000
    cosine_factor: 0.1
    lr_ratio: 0.1
    warmup_iterations: 2520
    warmup_factor: 0.25

training:
  experiment_name: FashionFAE_composition
  batch_size: 40
  lr_scheduler: true
  max_updates: 42000
  log_interval: 10
  checkpoint_interval: 8400
  evaluation_interval: 840
  find_unused_parameters: true
  early_stop:
    criteria: fashioniq/r@k_fashioniq/avg
    minimize: false
  wandb:
    enabled: true

checkpoint:
  resume_pretrained: true
  resume_file: save/FashionFAE_maskvalue/best.ckpt
  pretrained_state_mapping:
    image_encoder: image_encoder
    model.bert: model.bert
